# python YijingCode/dataset.py
import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from pathlib import Path
import os

class DualStreamDataset(Dataset):
    """
    PyTorch Dataset for Dual-Stream Concept Bottleneck Model training on SD3.5 latents.
    
    Reads the metadata CSV generated by latent_embedding.py and lazy-loads the 
    corresponding text and image tensors.
    """
    def __init__(self, metadata_path, base_dir=None, transform=None):
        """
        Args:
            metadata_path (str or Path): Path to the metadata.csv file.
            base_dir (str or Path, optional): Root directory for relative paths in CSV. 
                                              Defaults to the parent directory of metadata_path.
            transform (callable, optional): Optional transform to be applied on a sample.
        """
        self.metadata = pd.read_csv(metadata_path)
        
        # Resolve base directory relative to CSV location if not provided
        if base_dir:
            self.base_dir = Path(base_dir)
        else:
            self.base_dir = Path(metadata_path).parent
            
        self.transform = transform

        # Concept Mappings (Hardcoded for your 2x2 grid)
        # Concept A: Smile (Not Smiling=0, Smiling=1)
        # Concept B: Hair Color (Black Hair=0, Blonde Hair=1)
        self.concept_map_a = {"Not Smiling": 0.0, "Smiling": 1.0}
        self.concept_map_b = {"Black Hair": 0.0, "Blonde Hair": 1.0}

        # Verification check - at least one data directory should exist
        has_text_dir = (self.base_dir / "text_embeddings").exists()
        has_image_dir = (self.base_dir / "image_trajectories").exists()
        if not has_text_dir and not has_image_dir:
             print(f"WARNING: Neither text_embeddings nor image_trajectories directories found at {self.base_dir}. Check your paths.")
        elif not has_text_dir:
             print(f"INFO: text_embeddings directory not found (expected when save_dynamic_text_embedding=True). Using image_trajectories only.")
        elif not has_image_dir:
             print(f"WARNING: image_trajectories directory not found at {self.base_dir}. Check your paths.")

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        row = self.metadata.iloc[idx]

        # 1. Construct Full Paths
        # metadata.csv stores relative paths like "image_trajectories/..."
        text_path = self.base_dir / row['text_embedding_path']
        image_path = self.base_dir / row['image_latent_path']

        # 2. Load Tensors (Lazy Loading)
        try:
            # Load with weights_only=True for security
            # Tensors saved from latent_embedding.py are Float32 (converted from BFloat16).
            # We ensure Float32 for CBM training stability.
            text_emb = torch.load(text_path, map_location='cpu', weights_only=True)
            if text_emb.dtype != torch.float32:
                text_emb = text_emb.float()
            
            image_lat = torch.load(image_path, map_location='cpu', weights_only=True)
            if image_lat.dtype != torch.float32:
                image_lat = image_lat.float()
        except FileNotFoundError as e:
            raise FileNotFoundError(f"Missing tensor file for index {idx}. Expected at: {text_path} or {image_path}")
        except Exception as e:
            raise RuntimeError(f"Error loading tensor files for index {idx}. Text: {text_path}, Image: {image_path}. Error: {e}")

        # 3. Create Label Tensor [Concept_A, Concept_B]
        # We look up the string values from CSV in our map
        val_a = self.concept_map_a[row['concept_a']]
        val_b = self.concept_map_b[row['concept_b']]
        
        labels = torch.tensor([val_a, val_b], dtype=torch.float32)

        # 4. Shape Handling (Squeeze batch dim if present)
        # latent_embedding.py saves as [1, seq_len, hidden_dim] -> we want [seq_len, hidden_dim]
        # Expected: text_emb [1, 333, 1536] -> [333, 1536], image_lat [1, 2304, 1536] -> [2304, 1536]
        if text_emb.dim() == 3 and text_emb.shape[0] == 1:
            text_emb = text_emb.squeeze(0)
        elif text_emb.dim() != 2:
            raise ValueError(f"Unexpected text_emb shape: {text_emb.shape}. Expected [1, 333, 1536] or [333, 1536]")
            
        if image_lat.dim() == 3 and image_lat.shape[0] == 1:
            image_lat = image_lat.squeeze(0)
        elif image_lat.dim() != 2:
            raise ValueError(f"Unexpected image_lat shape: {image_lat.shape}. Expected [1, 2304, 1536] or [2304, 1536]")

        sample = {
            'text_emb': text_emb,       # Input for Text CBM
            'image_lat': image_lat,     # Input for Image CBM
            'labels': labels,           # Target for Concept Alignment Loss
            'timestep': row['timestep'], # Metadata (useful for logging/filtering)
            'prompt_id': row['prompt_id']
        }

        if self.transform:
            sample = self.transform(sample)

        return sample

def get_dataloader(data_dir, batch_size=32, shuffle=True, num_workers=4):
    """Factory function to get a ready-to-use DataLoader."""
    metadata_path = Path(data_dir) / "metadata.csv"
    dataset = DualStreamDataset(metadata_path=metadata_path)
    
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True # Optimization for CUDA transfer
    )

# ==========================================
# Verification Block (Run this file directly)
# ==========================================
if __name__ == "__main__":
    # Adjust this to point to your generated data folder
    DATA_DIR = "YijingCode/TrainingData" 
    
    print(f"--- Verifying Dataset at {DATA_DIR} ---")
    
    if not os.path.exists(os.path.join(DATA_DIR, "metadata.csv")):
        print("❌ Error: metadata.csv not found. Run generation script first.")
    else:
        try:
            # 1. Test Dataset Initialization
            ds = DualStreamDataset(os.path.join(DATA_DIR, "metadata.csv"))
            print(f"✅ Dataset Initialized. Size: {len(ds)}")
            
            # 2. Test Single Item Access
            idx = 0
            sample = ds[idx]
            print(f"\n[Sample {idx} Inspection]")
            print(f"  - Text Shape: {sample['text_emb'].shape} (Expected: [333, 1536])")
            print(f"  - Image Shape: {sample['image_lat'].shape} (Expected: [2304, 1536])")
            print(f"  - Label: {sample['labels']} (Expected: [0., 1.] etc)")
            print(f"  - Timestep: {sample['timestep']}")
            
            # 3. Test DataLoader (Batching)
            print(f"\n[DataLoader Test]")
            loader = get_dataloader(DATA_DIR, batch_size=4, num_workers=0) # workers=0 for simple debug
            batch = next(iter(loader))
            
            print(f"  - Batch Text Shape: {batch['text_emb'].shape} (Expected: [4, 333, 1536])")
            print(f"  - Batch Image Shape: {batch['image_lat'].shape} (Expected: [4, 2304, 1536])")
            print(f"  - Batch Labels: \n{batch['labels']}")
            print("\n✅ Verification Successful. You are ready to train.")
            
        except Exception as e:
            print(f"\n❌ Error during verification: {e}")
            import traceback
            traceback.print_exc()
